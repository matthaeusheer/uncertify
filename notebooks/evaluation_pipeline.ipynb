{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from context import uncertify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from uncertify.log import setup_logging\n",
    "setup_logging()\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "# Matplotlib DEBUG logging spits out a whole bunch of crap\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from uncertify.models.vae import load_vae_baur_model\n",
    "from uncertify.data.dataloaders import DatasetType\n",
    "from uncertify.data.dataloaders import dataloader_factory\n",
    "from uncertify.evaluation.evaluation_pipeline import run_evaluation_pipeline, print_results\n",
    "from uncertify.evaluation.configs import EvaluationConfig, PerformanceEvaluationConfig, PixelThresholdSearchConfig\n",
    "from uncertify.data.datasets import GaussianNoiseDataset\n",
    "from uncertify.common import DATA_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some paths and high level parameters\n",
    "CHECKPOINT_PATH = Path('/media/juniors/2TB_internal_HD/lightning_logs/train_vae/version_3/checkpoints/last.ckpt')\n",
    "SSD_PROCESSED_DIR_PATH = Path('/home/juniors/code/uncertify/data/processed/') \n",
    "HDD_PROCESSED_DIR_PATH = Path('/media/juniors/2TB_internal_HD/datasets/processed/')\n",
    "PROCESSED_DIR_PATH = SSD_PROCESSED_DIR_PATH\n",
    "\n",
    "BATCH_SIZE = 155\n",
    "USE_N_BATCHES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and define the evaluation config\n",
    "model = load_vae_baur_model(CHECKPOINT_PATH)\n",
    "eval_cfg = EvaluationConfig()\n",
    "eval_cfg.do_plots = False\n",
    "eval_cfg.use_n_batches = USE_N_BATCHES\n",
    "\n",
    "PROCESSED_DIR_PATH = Path('/media/juniors/2TB_internal_HD/datasets/processed/')\n",
    "\n",
    "brats_t2_path    = PROCESSED_DIR_PATH / 'brats17_t2_bc_std_bv3.5_l10.hdf5'\n",
    "brats_t2_hm_path = PROCESSED_DIR_PATH / 'brats17_t2_hm_bc_std_bv-3.5.hdf5'\n",
    "brats_t1_path    = PROCESSED_DIR_PATH / 'brats17_t1_bc_std_bv3.5_l10.hdf5'\n",
    "brats_t1_hm_path = PROCESSED_DIR_PATH / 'brats17_t1_hm_bc_std_bv-3.5.hdf5'\n",
    "camcan_t2_val_path   = DATA_DIR_PATH  / 'processed/camcan_val_t2_hm_std_bv3.5_xe.hdf5'\n",
    "camcan_t2_train_path = DATA_DIR_PATH  / 'processed/camcan_train_t2_hm_std_bv3.5_xe.hdf5'\n",
    "\n",
    "_, brats_val_t2_dataloader    = dataloader_factory(DatasetType.BRATS17, batch_size=BATCH_SIZE, val_set_path=brats_t2_path, shuffle_val=False)\n",
    "_, brats_val_t1_dataloader    = dataloader_factory(DatasetType.BRATS17, batch_size=BATCH_SIZE, val_set_path=brats_t1_path, shuffle_val=False)\n",
    "_, brats_val_t2_hm_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=BATCH_SIZE, val_set_path=brats_t2_hm_path, shuffle_val=False)\n",
    "_, brats_val_t1_hm_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=BATCH_SIZE, val_set_path=brats_t1_hm_path, shuffle_val=False)\n",
    "\n",
    "camcan_train_dataloader, camcan_val_dataloader = dataloader_factory(DatasetType.CAMCAN, batch_size=BATCH_SIZE, val_set_path=camcan_t2_val_path, train_set_path=camcan_t2_train_path, shuffle_val=False, shuffle_train=True)\n",
    "\n",
    "noise_set = GaussianNoiseDataset()\n",
    "noise_loader = DataLoader(noise_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "_, mnist_val_dataloader = dataloader_factory(DatasetType.MNIST, batch_size=BATCH_SIZE, transform=torchvision.transforms.Compose([\n",
    "                                                                        torchvision.transforms.Resize((128, 128)),\n",
    "                                                                        torchvision.transforms.ToTensor()]))\n",
    "\n",
    "for name, dataloader in [('BraTS T2 val', brats_val_t2_dataloader), \n",
    "                         ('BraTS T1 val', brats_val_t1_dataloader), \n",
    "                         ('BraTS T2 HM val', brats_val_t2_hm_dataloader), \n",
    "                         ('BraTS T1 HM val', brats_val_t1_hm_dataloader),\n",
    "                         ('CamCAN train', camcan_train_dataloader),\n",
    "                         ('Gaussian noise', noise_loader),\n",
    "                         ('MNIST', mnist_val_dataloader)\n",
    "                        ]: \n",
    "    print(f'{name:15} dataloader: {len(dataloader)} batches (batch_size: {dataloader.batch_size}) -> {len(dataloader) * dataloader.batch_size} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_SEGMENTATION      = True\n",
    "DO_ANOMALY_DETECTION = True\n",
    "DO_HISTOGRAMS        = False\n",
    "DO_OOD               = False\n",
    "RESIDUAL_THRESHOLD  = 1.35\n",
    "\n",
    "results = {}\n",
    "\n",
    "counter = 0\n",
    "for dataloader, name in zip([brats_val_t2_hm_dataloader, brats_val_t1_hm_dataloader, brats_val_t2_dataloader, brats_val_t1_dataloader],\n",
    "                            ['BraTS T2 HM', 'BraTS T1 HM', 'BraTS T2', 'BraTS T1']):\n",
    "    LOG.info(f'Running evaluation on {name}!')\n",
    "    result = run_evaluation_pipeline(model, \n",
    "                                    camcan_train_dataloader, \n",
    "                                    dataloader, \n",
    "                                    eval_cfg, \n",
    "                                    RESIDUAL_THRESHOLD,\n",
    "                                    run_segmentation=DO_SEGMENTATION, \n",
    "                                    run_anomaly_detection=DO_ANOMALY_DETECTION, \n",
    "                                    run_histograms=DO_HISTOGRAMS,\n",
    "                                    run_ood_detection=DO_OOD)\n",
    "    results[name] = result\n",
    "    counter += 1\n",
    "    if counter == 2:\n",
    "        pass\n",
    "    \n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f'\\n\\t{name}')\n",
    "    print_results(result)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertify-env",
   "language": "python",
   "name": "uncertify-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
