{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from context import uncertify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from uncertify.log import setup_logging\n",
    "setup_logging()\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "# Matplotlib DEBUG logging spits out a whole bunch of crap\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import Compose\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='serif')\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "from uncertify.models.vae import VariationalAutoEncoder\n",
    "from uncertify.models.encoder_decoder_baur2020 import BaurDecoder, BaurEncoder\n",
    "from uncertify.data.dataloaders import dataloader_factory, DatasetType\n",
    "from uncertify.visualization.reconstruction import plot_stacked_scan_reconstruction_batches\n",
    "from uncertify.deploy import yield_reconstructed_batches\n",
    "from uncertify.visualization.grid import imshow_grid\n",
    "from uncertify.visualization.plotting import setup_plt_figure\n",
    "from uncertify.evaluation.thresholding import threshold_vs_fpr\n",
    "from uncertify.algorithms.golden_section_search import golden_section_search\n",
    "from uncertify.evaluation.thresholding import calculate_fpr_minus_accepted\n",
    "from uncertify.evaluation.model_performance import calculate_mean_dice_score, calculate_mean_dice_scores\n",
    "from uncertify.common import DATA_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalAutoEncoder(BaurEncoder(), BaurDecoder(), get_batch_fn=lambda batch: batch['scan'])\n",
    "model_mnist = VariationalAutoEncoder(BaurEncoder(), BaurDecoder(), get_batch_fn=lambda batch: batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = DATA_DIR_PATH / 'lightning_logs/train_vae/version_1/checkpoints/epoch=261.ckpt'\n",
    "assert CHECKPOINT_PATH.exists(), f'Model checkpoint does not exist!'\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, brats_val_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=8, shuffle_val=True)\n",
    "camcan_train_dataloader, camcan_val_dataloader = dataloader_factory(DatasetType.CAMCAN, batch_size=8, shuffle_train=True, shuffle_val=True)\n",
    "mnist_train_dataloader, mnist_val_dataloader = dataloader_factory(DatasetType.MNIST, batch_size=8, shuffle_train=True, shuffle_val=True,\n",
    "                                                                 transform=Compose([torchvision.transforms.Resize((128, 128)),\n",
    "                                                                          torchvision.transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_batches = 1\n",
    "\n",
    "batch_generator = yield_reconstructed_batches(camcan_train_dataloader, model, residual_threshold=0.16)\n",
    "plot_stacked_scan_reconstruction_batches(batch_generator, plot_n_batches, \n",
    "                                         cmap='hot', axis='off', figsize=(20, 20), save_dir_path=DATA_DIR_PATH/'reconstructions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertify.evaluation.model_performance import calculate_mean_dice_scores, calculate_mean_iou_scores\n",
    "from uncertify.visualization.model_performance import plot_segmentation_performance_vs_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_calc_thresholds = np.linspace(0, 1, 10)\n",
    "dice_scores = calculate_mean_dice_scores(brats_val_dataloader, model, residual_thresholds=performance_calc_thresholds,\n",
    "                                         max_n_batches=5)\n",
    "iou_scores = calculate_mean_iou_scores(brats_val_dataloader, model, residual_thresholds=performance_calc_thresholds,\n",
    "                                       max_n_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_segmentation_performance_vs_threshold(performance_calc_thresholds, dice_scores=dice_scores, iou_scores=iou_scores, \n",
    "                                                    train_set_threshold=0.17, figsize=(12, 6));\n",
    "fig.savefig(DATA_DIR_PATH / 'plots' / 'dice_iou_vs_threshold.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel-wise anomaly detection / classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertify.evaluation.model_performance import calculate_confusion_matrix\n",
    "from uncertify.visualization.model_performance import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = calculate_confusion_matrix(brats_val_dataloader, model, residual_threshold=0.17, max_n_batches=10, normalize=None)\n",
    "fig, _ = plot_confusion_matrix(confusion_matrix, categories=['normal', 'anomaly'], cbar=False, cmap='YlGn', figsize=(7, 6))\n",
    "fig.savefig(DATA_DIR_PATH / 'plots' / 'confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertify.deploy import yield_y_true_y_pred\n",
    "from scikitplot.metrics import plot_precision_recall, plot_roc\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = yield_y_true_y_pred(brats_val_dataloader, model, max_n_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprc = average_precision_score(y_true, y_pred[:, 1])\n",
    "%time ax = plot_precision_recall(y_true, y_pred, figsize=(12, 8), classes_to_plot=[1], plot_micro=False, title=f'PR Curve Pixel-wise Anomaly Detection')\n",
    "plt.savefig(DATA_DIR_PATH / 'plots' / 'precision_recall_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = roc_auc_score(y_true, y_pred[:, 1])\n",
    "%time ax = plot_roc(y_true, y_pred, figsize=(12, 8), plot_micro=False, plot_macro=False, classes_to_plot=[1], title=f'ROC Curve Pixel-wise Anomaly Detection')\n",
    "plt.savefig(DATA_DIR_PATH / 'plots' / 'roc_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample-wise Loss Term Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from uncertify.visualization.histograms import plot_loss_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_batches = 5\n",
    "\n",
    "brats_val_generator = yield_reconstructed_batches(brats_val_dataloader, model, residual_threshold=0.16, max_batches=max_n_batches)\n",
    "camcan_val_generator = yield_reconstructed_batches(camcan_val_dataloader, model, residual_threshold=0.16, max_batches=max_n_batches)\n",
    "mnist_val_generator = yield_reconstructed_batches(mnist_val_dataloader, model_mnist, residual_threshold=0.16, max_batches=max_n_batches, get_batch_fn=lambda batch: batch[0])\n",
    "output_generators = [brats_val_generator, camcan_val_generator, mnist_val_generator]\n",
    "generator_names = ['BraTS17 Val', 'CamCAN Val', 'MNIST Val']\n",
    "figs_axes = plot_loss_histograms(output_generators=output_generators, names=generator_names, figsize=(12, 4), ylabel='Normalized Frequency', plot_density=True)\n",
    "for idx, (fig, _) in enumerate(figs_axes):\n",
    "    fig.savefig(DATA_DIR_PATH / 'plots' / f'loss_term_distributions_{idx}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in brats_val_dataloader:\n",
    "    for sample in batch['seg']:\n",
    "        print(sample.shape)\n",
    "        print(sample.numel())\n",
    "        print(sample > 0)\n",
    "        print(torch.sum(sample > 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "thresholds, camcan_false_positive_rates = threshold_vs_fpr(camcan_train_dataloader, model, thresholds=np.linspace(0, 1, 20),\n",
    "                                                    use_ground_truth=False, n_batches_per_thresh=200)\n",
    "thresholds, brats_false_positive_rates = threshold_vs_fpr(brats_val_dataloader, model, thresholds=np.linspace(0, 1, 20),\n",
    "                                                    use_ground_truth=False, n_batches_per_thresh=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the threshold value which secures a certain FPR on the training data\n",
    "ACCEPTED_FPR = 0.05\n",
    "\n",
    "objective = partial(calculate_fpr_minus_accepted, \n",
    "                    accepted_fpr=ACCEPTED_FPR,\n",
    "                    data_loader=camcan_train_dataloader, \n",
    "                    model=model, \n",
    "                    use_ground_truth=False, \n",
    "                    n_batches_per_thresh=10)\n",
    "tau = golden_section_search(objective, low=0.0, up=1.0, tolerance=0.003)\n",
    "mean_tau = np.mean(tau)\n",
    "print(f'Found threshold value: {mean_tau}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "fig, ax = setup_plt_figure(figsize=(16, 8))\n",
    "ax.plot(thresholds, camcan_false_positive_rates, linewidth=4, linestyle='dashed', alpha=0.5, label='CamCAN Train')\n",
    "ax.plot(thresholds, brats_false_positive_rates, linewidth=3, linestyle='solid', alpha=0.7, label='BraTS Validation')\n",
    "ax.set_ylabel(f'False Positive Rate')\n",
    "ax.set_xlabel(f'Threshold')\n",
    "\n",
    "normed_diff = [abs(fpr - ACCEPTED_FPR) for fpr in camcan_false_positive_rates]\n",
    "ax.plot(thresholds, normed_diff, c='green', alpha=0.7, linewidth=3, label='CamCAN FPR - Accepted FPR')\n",
    "ax.plot(thresholds, [ACCEPTED_FPR] * len(thresholds), linestyle='dotted', linewidth=3, color='grey', label=f'Accepted FPR ({ACCEPTED_FPR:.2f})')\n",
    "ax.plot([mean_tau, mean_tau], [-0.05, 1], linestyle='dotted', color='green', linewidth=3, label=f'Threshold through Golden Section Search ({mean_tau:.2f})')\n",
    "ax.legend(frameon=False)\n",
    "fig.savefig(DATA_DIR_PATH / 'plots' / 'threshold.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}