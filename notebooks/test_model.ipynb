{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from context import uncertify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from uncertify.log import setup_logging\n",
    "setup_logging()\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "# Matplotlib DEBUG logging spits out a whole bunch of crap\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    tqdm._instances.clear()\n",
    "except:\n",
    "    pass\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "plt.rc('font', family='serif')\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from uncertify.models.vae import VariationalAutoEncoder\n",
    "from uncertify.models.encoder_decoder_baur2020 import BaurDecoder, BaurEncoder\n",
    "from uncertify.data.dataloaders import dataloader_factory, DatasetType\n",
    "from uncertify.visualization.reconstruction import plot_stacked_scan_reconstruction_batches\n",
    "from uncertify.visualization.model_performance import plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix\n",
    "from uncertify.evaluation.inference import yield_inference_batches, yield_y_true_y_pred\n",
    "from uncertify.visualization.grid import imshow_grid\n",
    "from uncertify.visualization.plotting import setup_plt_figure\n",
    "from uncertify.evaluation.thresholding import threshold_vs_fpr\n",
    "from uncertify.algorithms.golden_section_search import golden_section_search\n",
    "from uncertify.evaluation.thresholding import calculate_fpr_minus_accepted\n",
    "from uncertify.data.datasets import GaussianNoiseDataset\n",
    "\n",
    "from uncertify.common import DATA_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalAutoEncoder(BaurEncoder(), BaurDecoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT_PATH = DATA_DIR_PATH / 'models/last.ckpt'\n",
    "assert CHECKPOINT_PATH.exists(), f'Model checkpoint does not exist!'\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS T2 val    dataloader: 4941 batches (batch_size: 8) -> 39528 samples.\n",
      "BraTS T1 val    dataloader: 4941 batches (batch_size: 8) -> 39528 samples.\n",
      "CamCAN train    dataloader: 9518 batches (batch_size: 8) -> 76144 samples.\n",
      "Gaussian noise  dataloader: 1250 batches (batch_size: 8) -> 10000 samples.\n",
      "MNIST           dataloader: 1250 batches (batch_size: 8) -> 10000 samples.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "HDD_PROCESSED_DIR_PATH = Path('/media/juniors/2TB_internal_HD/datasets/processed/')\n",
    "SSD_PROCESSED_DIR_PATH = DATA_DIR_PATH / 'processed'\n",
    "\n",
    "_, brats_val_t2_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, \n",
    "                                             val_set_path=SSD_PROCESSED_DIR_PATH / 'brats17_t2_hm_bc_std_bv-3.5.hdf5', shuffle_val=True)\n",
    "_, brats_val_t1_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, \n",
    "                                             val_set_path=SSD_PROCESSED_DIR_PATH / 'brats17_t1_hm_bc_std_bv-3.5.hdf5', shuffle_val=True)\n",
    "camcan_train_dataloader, camcan_val_dataloader = dataloader_factory(DatasetType.CAMCAN, batch_size=batch_size, \n",
    "                                                                    val_set_path=DATA_DIR_PATH / 'processed/camcan_val_t2_hm_std_bv3.5_xe.hdf5', \n",
    "                                                                    train_set_path=DATA_DIR_PATH / 'processed/camcan_train_t2_hm_std_bv3.5_xe.hdf5', \n",
    "                                                                    shuffle_val=False, shuffle_train=True)\n",
    "noise_set = GaussianNoiseDataset()\n",
    "noise_loader = DataLoader(noise_set, batch_size=batch_size)\n",
    "\n",
    "_, mnist_val_dataloader = dataloader_factory(DatasetType.MNIST, batch_size=batch_size, transform=torchvision.transforms.Compose([\n",
    "                                                                        torchvision.transforms.Resize((128, 128)),\n",
    "                                                                        torchvision.transforms.ToTensor()\n",
    "                                                                    ])\n",
    "                         )\n",
    "\n",
    "for name, dataloader in [('BraTS T2 val', brats_val_t2_dataloader), \n",
    "                         ('BraTS T1 val', brats_val_t1_dataloader), \n",
    "                         ('CamCAN train', camcan_train_dataloader),\n",
    "                         ('Gaussian noise', noise_loader),\n",
    "                         ('MNIST', mnist_val_dataloader)\n",
    "                        ]: \n",
    "    print(f'{name:15} dataloader: {len(dataloader)} batches (batch_size: {dataloader.batch_size}) -> {len(dataloader) * dataloader.batch_size} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.tensor(range(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.4 ms, sys: 0 ns, total: 81.4 ms\n",
      "Wall time: 80.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for item in t.numpy():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Pixel-Wise Anomaly Detection Performance (ROC & PRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred_proba, y_pred = yield_y_true_y_pred(brats_val_t2_dataloader, model, residual_threshold=0.26, max_n_batches=10)\n",
    "\n",
    "fpr, tpr, roc_threshs = roc_curve(y_true, y_pred_proba)\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "precision, recall, prc_threshs = precision_recall_curve(y_true, y_pred_proba)\n",
    "auprc = average_precision_score(y_true, y_pred_proba)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "fig_conf_mat, _ = plot_confusion_matrix(conf_matrix, categories=['normal', 'anomaly'], cbar=False, cmap='YlOrRd_r', figsize=(5, 5))\n",
    "fig_roc = plot_roc_curve(fpr, tpr, auc, 0.9, roc_threshs, figsize=(5, 5));\n",
    "fig_prc = plot_precision_recall_curve(recall, precision, auprc, 0.9, prc_threshs, figsize=(5,5));\n",
    "\n",
    "fig_conf_mat.savefig(DATA_DIR_PATH / 'plots' / 'confusion_matrix.png')\n",
    "fig_roc.savefig(DATA_DIR_PATH / 'plots' / 'roc_curve.png')\n",
    "fig_prc.savefig(DATA_DIR_PATH / 'plots' / 'prc_curve.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_batches = 1\n",
    "\n",
    "# CamCAN\n",
    "batch_generator = yield_inference_batches(camcan_val_dataloader, model, residual_threshold=0.3)\n",
    "plot_stacked_scan_reconstruction_batches(batch_generator, plot_n_batches, \n",
    "                                         cmap='hot', axis='off', figsize=(20, 20), save_dir_path=DATA_DIR_PATH/'reconstructions')\n",
    "\n",
    "# BraTS\n",
    "for brats_dataloader in [brats_val_t2_dataloader, brats_val_t1_dataloader, noise_loader, mnist_val_dataloader]:\n",
    "    batch_generator = yield_inference_batches(brats_dataloader, model, residual_threshold=0.3)\n",
    "    plot_stacked_scan_reconstruction_batches(batch_generator, plot_n_batches, \n",
    "                                             cmap='hot', axis='off', figsize=(20, 20), save_dir_path=DATA_DIR_PATH/'reconstructions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertify.evaluation.model_performance import mean_std_dice_scores, mean_std_iou_scores\n",
    "from uncertify.visualization.model_performance import plot_segmentation_performance_vs_threshold\n",
    "try:\n",
    "    tqdm._instances.clear()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_thresholds = 3\n",
    "max_n_batches = 10\n",
    "\n",
    "pixel_thresholds = np.linspace(0, 3.0, n_thresholds)\n",
    "mean_dice_scores, std_dice_scores = mean_std_dice_scores(brats_val_t2_dataloader, model, residual_thresholds=pixel_thresholds, max_n_batches=max_n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_segmentation_performance_vs_threshold(pixel_thresholds, dice_scores=mean_dice_scores, dice_stds=std_dice_scores, iou_scores=None, \n",
    "                                                    train_set_threshold=None, figsize=(12, 6));\n",
    "fig.savefig(DATA_DIR_PATH / 'plots' / 'dice_iou_vs_threshold.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample-wise Loss Term Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from uncertify.visualization.histograms import plot_loss_histograms\n",
    "try:\n",
    "    tqdm._instances.clear()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_batches = 30\n",
    "redisual_threshold = 0.25\n",
    "\n",
    "dataloaders = [camcan_train_dataloader,\n",
    "               brats_val_t1_dataloader, \n",
    "               brats_val_t2_dataloader, \n",
    "               mnist_val_dataloader,\n",
    "               noise_loader]\n",
    "\n",
    "generator_names = ['CamCAN Train T2', \n",
    "                   'BraTS17 T1',\n",
    "                   'BraTS17 T2',\n",
    "                   'MNIST Val',\n",
    "                   'Gaussian Noise']\n",
    "\n",
    "output_generators = []\n",
    "for dataloader, name in zip(dataloaders, generator_names):\n",
    "    output_generators.append(yield_inference_batches(dataloader, model, max_n_batches, redisual_threshold, progress_bar_suffix=f'{name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_axes = plot_loss_histograms(output_generators=output_generators, names=generator_names, \n",
    "                                 figsize=(12, 6), ylabel='Normalized Frequency', plot_density=True, show_data_ticks=False, kde_bandwidth=[0.009, 0.009*5.5], show_histograms=False)\n",
    "\n",
    "for idx, (fig, _) in enumerate(figs_axes):\n",
    "    fig.savefig(DATA_DIR_PATH / 'plots' / f'loss_term_distributions_{idx}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertify.visualization.latent_space_analysis import plot_umap_latent_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_batches = 10\n",
    "redisual_threshold = 0.25\n",
    "\n",
    "dataloaders = [brats_val_t1_dataloader, \n",
    "               brats_val_t2_dataloader, \n",
    "               mnist_val_dataloader,\n",
    "               noise_loader,\n",
    "               camcan_train_dataloader,\n",
    "]\n",
    "\n",
    "generator_names = ['BraTS17 T1',\n",
    "                   'BraTS17 T2',\n",
    "                   'MNIST Val',\n",
    "                   'Gaussian Noise',\n",
    "                   'CamCAN Train T2']\n",
    "\n",
    "output_generators = []\n",
    "for dataloader, name in zip(dataloaders, generator_names):\n",
    "    output_generators.append(yield_inference_batches(dataloader, model, max_n_batches, redisual_threshold, progress_bar_suffix=f'{name}'))\n",
    "\n",
    "umap_fig = plot_umap_latent_embedding(output_generators, generator_names, figsize=(14, 10))\n",
    "umap_fig.savefig(DATA_DIR_PATH / 'plots' / f'umap_latent_embedding.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from uncertify.visualization.threshold_search import plot_fpr_vs_residual_threshold\n",
    "try:\n",
    "    tqdm._instances.clear()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_thresholds = np.linspace(0, 1, 4)\n",
    "thresholds, camcan_false_positive_rates = threshold_vs_fpr(camcan_train_dataloader, model, thresholds=pixel_thresholds,\n",
    "                                                    use_ground_truth=False, n_batches_per_thresh=10)\n",
    "thresholds, brats_false_positive_rates = threshold_vs_fpr(brats_val_dataloader, model, thresholds=pixel_thresholds,\n",
    "                                                    use_ground_truth=False, n_batches_per_thresh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the threshold value which secures a certain FPR on the training data\n",
    "ACCEPTED_FPR = 0.05\n",
    "\n",
    "objective = partial(calculate_fpr_minus_accepted, \n",
    "                    accepted_fpr=ACCEPTED_FPR,\n",
    "                    data_loader=camcan_train_dataloader, \n",
    "                    model=model, \n",
    "                    use_ground_truth=False, \n",
    "                    n_batches_per_thresh=10)\n",
    "best_thresholds = golden_section_search(objective, low=0.0, up=1.0, tolerance=0.003)\n",
    "best_threshold = np.mean(best_thresholds)\n",
    "print(f'Found threshold value: {best_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_fpr_vs_residual_threshold(accepted_fpr=ACCEPTED_FPR, \n",
    "                                     calculated_threshold=best_threshold, \n",
    "                                     thresholds=thresholds, \n",
    "                                     fpr_train=camcan_false_positive_rates, \n",
    "                                     fpr_val=brats_false_positive_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot MNIST reconstructions\n",
    "Run various MNIST examples (batches consisting of samples of a certain number) through the model and plot input and reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_batches = 1\n",
    "batch_size = 8\n",
    "for n in range(0, 10):\n",
    "    _, mnist_val_dataloader = dataloader_factory(DatasetType.MNIST, batch_size=batch_size, transform=torchvision.transforms.Compose([\n",
    "                                                                        torchvision.transforms.Resize((128, 128)),\n",
    "                                                                        torchvision.transforms.ToTensor()\n",
    "                                                                    ]),\n",
    "                         mnist_label=n)\n",
    "    batch_generator = yield_inference_batches(mnist_val_dataloader, model, residual_threshold=0.3)\n",
    "    plot_stacked_scan_reconstruction_batches(batch_generator, plot_n_batches, \n",
    "                                             cmap='hot', axis='off', figsize=(15, 15), save_dir_path=DATA_DIR_PATH/'reconstructions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot latent space sample reconstructions from different locations in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertify.visualization.latent_space_analysis import plot_latent_samples_from_ring\n",
    "\n",
    "radii = [(0, 1), (2, 3), (4, 5), (50, 70), (200, 210), (240, 250)]\n",
    "\n",
    "for sample in radii:\n",
    "    inner_radius, outer_radius = sample\n",
    "    fig = plot_latent_samples_from_ring(model, n_samples=8, inner_radius=inner_radius, outer_radius=outer_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
