{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from context import uncertify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from uncertify.log import setup_logging\n",
    "setup_logging()\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "# Matplotlib DEBUG logging spits out a whole bunch of crap\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    tqdm._instances.clear()\n",
    "except:\n",
    "    pass\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "plt.rc('font', family='serif')\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "from uncertify.data.np_transforms import NumpyReshapeTransform, Numpy2PILTransform\n",
    "from uncertify.data.datasets import GaussianNoiseDataset\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from uncertify.models.vae import load_vae_baur_model\n",
    "from uncertify.models.vae import VariationalAutoEncoder\n",
    "from uncertify.models.encoder_decoder_baur2020 import BaurDecoder, BaurEncoder\n",
    "\n",
    "from uncertify.data.dataloaders import dataloader_factory, DatasetType\n",
    "\n",
    "from uncertify.evaluation.inference import yield_inference_batches\n",
    "from uncertify.evaluation.ood_metrics import sample_wise_waic_scores\n",
    "from uncertify.evaluation.ood_metrics import load_ensemble_models\n",
    "from uncertify.evaluation.evaluation_pipeline import run_ood_detection_performance, EvaluationConfig, EvaluationResult, PixelAnomalyDetectionResult, SliceAnomalyDetectionResults, OODDetectionResult\n",
    "\n",
    "\n",
    "from uncertify.visualization.grid import imshow_grid\n",
    "from uncertify.visualization.model_performance import plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix\n",
    "from uncertify.visualization.plotting import setup_plt_figure\n",
    "from uncertify.visualization.histograms import plot_multi_histogram\n",
    "\n",
    "from uncertify.common import DATA_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some paths and high level parameters\n",
    "RUN_DIR_PATH = Path('/media/juniors/2TB_internal_HD/lightning_logs/train_vae/')\n",
    "RUN_VERSIONS = [0, 1, 2, 3]\n",
    "CHECKPOINT_PATHS = [RUN_DIR_PATH / f'version_{version}/checkpoints/last.ckpt' for version in RUN_VERSIONS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = load_ensemble_models(DATA_DIR_PATH / 'ensemble_models', [f'model{idx}.ckpt' for idx in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 155\n",
    "USE_N_BATCHES = 5\n",
    "\n",
    "PROCESSED_DIR_PATH = Path('/media/juniors/2TB_internal_HD/datasets/processed/')\n",
    "\n",
    "brats_t2_path    = PROCESSED_DIR_PATH / 'brats17_t2_bc_std_bv3.5_l10.hdf5'\n",
    "brats_t2_hm_path = PROCESSED_DIR_PATH / 'brats17_t2_hm_bc_std_bv-3.5.hdf5'\n",
    "brats_t1_path    = PROCESSED_DIR_PATH / 'brats17_t1_bc_std_bv3.5_l10.hdf5'\n",
    "brats_t1_hm_path = PROCESSED_DIR_PATH / 'brats17_t1_hm_bc_std_bv-3.5.hdf5'\n",
    "camcan_t2_val_path   = DATA_DIR_PATH  / 'processed/camcan_val_t2_hm_std_bv3.5_xe.hdf5'\n",
    "camcan_t2_train_path = DATA_DIR_PATH  / 'processed/camcan_train_t2_hm_std_bv3.5_xe.hdf5'\n",
    "\n",
    "_, brats_val_t2_dataloader    = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_path, shuffle_val=False, num_workers=12)\n",
    "_, brats_val_t1_dataloader    = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t1_path, shuffle_val=False, num_workers=12)\n",
    "_, brats_val_t2_hm_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_hm_path, shuffle_val=False, num_workers=12)\n",
    "_, brats_val_t1_hm_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t1_hm_path, shuffle_val=False, num_workers=12)\n",
    "\n",
    "hflip_transform = torchvision.transforms.Compose([\n",
    "    NumpyReshapeTransform((200, 200)),\n",
    "    Numpy2PILTransform(),\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "vflip_transform = torchvision.transforms.Compose([\n",
    "    NumpyReshapeTransform((200, 200)),\n",
    "    Numpy2PILTransform(),\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=1.0),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "_, brats_val_t2_hm_hflip_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_hm_path, shuffle_val=False, num_workers=12, transform=hflip_transform)\n",
    "_, brats_val_t1_hm_vflip_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t1_hm_path, shuffle_val=False, num_workers=12, transform=vflip_transform)\n",
    "\n",
    "camcan_train_dataloader, camcan_val_dataloader = dataloader_factory(DatasetType.CAMCAN, batch_size=batch_size, val_set_path=camcan_t2_val_path, train_set_path=camcan_t2_train_path, shuffle_val=False, shuffle_train=True, num_workers=12)\n",
    "\n",
    "noise_set = GaussianNoiseDataset()\n",
    "noise_loader = DataLoader(noise_set, batch_size=batch_size)\n",
    "\n",
    "_, mnist_val_dataloader = dataloader_factory(DatasetType.MNIST, batch_size=batch_size, transform=torchvision.transforms.Compose([\n",
    "                                                                        torchvision.transforms.Resize((128, 128)),\n",
    "                                                                        torchvision.transforms.ToTensor()\n",
    "                                                                    ])\n",
    "                         )\n",
    "\n",
    "dataloader_dict = {'BraTS T2 val': brats_val_t2_dataloader, \n",
    "                   'BraTS T1 val': brats_val_t1_dataloader, \n",
    "                   'BraTS T2 HM val': brats_val_t2_hm_dataloader, \n",
    "                   'BraTS T1 HM val': brats_val_t1_hm_dataloader,\n",
    "                   'CamCAN train': camcan_train_dataloader,\n",
    "                   'Gaussian noise': noise_loader,\n",
    "                   'MNIST': mnist_val_dataloader\n",
    "}\n",
    "\n",
    "for name, dataloader in dataloader_dict.items(): \n",
    "    print(f'{name:15} dataloader: {len(dataloader)} batches (batch_size: {dataloader.batch_size}) -> {len(dataloader) * dataloader.batch_size} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD Detection Evaluation for different OOD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_dataloders = {#'BraTS T2 val': brats_val_t2_dataloader, \n",
    "                    #'BraTS T1 val': brats_val_t1_dataloader, \n",
    "                    #'BraTS T2 HM val': brats_val_t2_hm_dataloader, \n",
    "                    #'BraTS T1 HM val': brats_val_t1_hm_dataloader,\n",
    "                    'BraTS T2 HM Hor. Flip': brats_val_t2_hm_hflip_dataloader, \n",
    "                    'BraTS T2 HM Vert. Flip': brats_val_t1_hm_vflip_dataloader, \n",
    "}\n",
    "\n",
    "for name, dataloader in brats_dataloders.items():\n",
    "    LOG.info(f'OOD evaluation for {name}...')\n",
    "    eval_cfg = EvaluationConfig()\n",
    "    eval_cfg.do_plots = True\n",
    "    eval_cfg.use_n_batches = USE_N_BATCHES\n",
    "    results = EvaluationResult(DATA_DIR_PATH / 'evaluation', PixelAnomalyDetectionResult(), SliceAnomalyDetectionResults(), OODDetectionResult())\n",
    "    results.pixel_anomaly_result.best_threshold = 1.35\n",
    "    results.make_dirs()\n",
    "    print(results.current_run_number)\n",
    "    \n",
    "    run_ood_detection_performance(ensemble_models, camcan_train_dataloader, dataloader, eval_cfg, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAIC Score Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BACTHES = 5\n",
    "\n",
    "waic_dict = {}\n",
    "for name, data_loader in dataloader_dict.items():\n",
    "    LOG.info(f'WAIC score calculation for {name} ({NUM_BACTHES * data_loader.batch_size} patients)...')\n",
    "    waic_scores = sample_wise_waic_scores(models=ensemble_models, data_loader=data_loader, max_n_batches=NUM_BACTHES)\n",
    "    waic_dict[name] = waic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_multi_histogram(waic_dict.values(), list(waic_dict.keys()), plot_density=False, \n",
    "                     figsize=(12, 6), xlabel='WAIC', ylabel='Slice-wise frequency',\n",
    "                     hist_kwargs={'bins': 15});\n",
    "fig.savefig(DATA_DIR_PATH / 'plots' / 'waic_scores.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertify-env",
   "language": "python",
   "name": "uncertify-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
