{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from context import uncertify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from uncertify.log import setup_logging\n",
    "setup_logging()\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "# Matplotlib DEBUG logging spits out a whole bunch of crap\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    tqdm._instances.clear()\n",
    "except:\n",
    "    pass\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "plt.rc('font', family='serif')\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "from uncertify.data.np_transforms import NumpyReshapeTransform, Numpy2PILTransform\n",
    "from uncertify.data.datasets import GaussianNoiseDataset\n",
    "\n",
    "from uncertify.data.dataloaders import dataloader_factory, DatasetType\n",
    "\n",
    "from uncertify.io.models import load_ensemble_models\n",
    "from uncertify.evaluation.ood_experiments import run_ood_evaluations, run_ood_to_ood_dict\n",
    "from uncertify.evaluation.configs import OODDetectionResults\n",
    "\n",
    "from uncertify.visualization.histograms import plot_multi_histogram\n",
    "from uncertify.visualization.ood_scores import plot_ood_scores, plot_most_least_ood, plot_samples_close_to_score\n",
    "from uncertify.visualization.grid import imshow_grid\n",
    "\n",
    "from uncertify.common import DATA_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some paths and high level parameters\n",
    "RUN_DIR_PATH = Path('/media/juniors/2TB_internal_HD/lightning_logs/train_vae/')\n",
    "RUN_VERSIONS = range(2)\n",
    "CHECKPOINT_PATHS = [RUN_DIR_PATH / f'version_{version}/checkpoints/last.ckpt' for version in RUN_VERSIONS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = load_ensemble_models(DATA_DIR_PATH / 'ensemble_models', [f'model{idx}.ckpt' for idx in RUN_VERSIONS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 155\n",
    "USE_N_BATCHES = 3\n",
    "\n",
    "PROCESSED_DIR_PATH = Path('/media/juniors/2TB_internal_HD/datasets/processed/')\n",
    "\n",
    "brats_t2_path    = PROCESSED_DIR_PATH / 'brats17_t2_bc_std_bv3.5_l10.hdf5'\n",
    "brats_t2_hm_path = PROCESSED_DIR_PATH / 'brats17_t2_hm_bc_std_bv-3.5.hdf5'\n",
    "brats_t1_path    = PROCESSED_DIR_PATH / 'brats17_t1_bc_std_bv3.5_l10.hdf5'\n",
    "brats_t1_hm_path = PROCESSED_DIR_PATH / 'brats17_t1_hm_bc_std_bv-3.5.hdf5'\n",
    "camcan_t2_val_path   = DATA_DIR_PATH  / 'processed/camcan_val_t2_hm_std_bv3.5_xe.hdf5'\n",
    "camcan_t2_train_path = DATA_DIR_PATH  / 'processed/camcan_train_t2_hm_std_bv3.5_xe.hdf5'\n",
    "\n",
    "_, brats_val_t2_dataloader    = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_path, shuffle_val=False, num_workers=12)\n",
    "_, brats_val_t1_dataloader    = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t1_path, shuffle_val=False, num_workers=12)\n",
    "_, brats_val_t2_hm_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_hm_path, shuffle_val=False, num_workers=12)\n",
    "_, brats_val_t1_hm_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t1_hm_path, shuffle_val=False, num_workers=12)\n",
    "\n",
    "hflip_transform = torchvision.transforms.Compose([\n",
    "    NumpyReshapeTransform((200, 200)),\n",
    "    Numpy2PILTransform(),\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "vflip_transform = torchvision.transforms.Compose([\n",
    "    NumpyReshapeTransform((200, 200)),\n",
    "    Numpy2PILTransform(),\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=1.0),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "_, brats_val_t2_hflip_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_path, shuffle_val=False, num_workers=12, transform=hflip_transform)\n",
    "_, brats_val_t2_vflip_dataloader = dataloader_factory(DatasetType.BRATS17, batch_size=batch_size, val_set_path=brats_t2_path, shuffle_val=False, num_workers=12, transform=vflip_transform)\n",
    "\n",
    "camcan_train_dataloader, camcan_val_dataloader = dataloader_factory(DatasetType.CAMCAN, batch_size=batch_size, val_set_path=camcan_t2_val_path, train_set_path=camcan_t2_train_path, shuffle_val=False, shuffle_train=True, num_workers=12)\n",
    "\n",
    "noise_set = GaussianNoiseDataset()\n",
    "noise_loader = DataLoader(noise_set, batch_size=batch_size)\n",
    "\n",
    "_, mnist_val_dataloader = dataloader_factory(DatasetType.MNIST, batch_size=batch_size, transform=torchvision.transforms.Compose([\n",
    "                                                                        torchvision.transforms.Resize((128, 128)),\n",
    "                                                                        torchvision.transforms.ToTensor()\n",
    "                                                                    ])\n",
    "                         )\n",
    "\n",
    "dataloader_dict = {'BraTS T2 val': brats_val_t2_dataloader, \n",
    "                   #'BraTS T1 val': brats_val_t1_dataloader, \n",
    "                   #'BraTS T2 HM val': brats_val_t2_hm_dataloader, \n",
    "                   #'BraTS T1 HM val': brats_val_t1_hm_dataloader,\n",
    "                   #'CamCAN train': camcan_train_dataloader,\n",
    "                   #'Gaussian noise': noise_loader,\n",
    "                   #'MNIST': mnist_val_dataloader,\n",
    "                   #'BraTS T2 HFlip': brats_val_t2_hflip_dataloader,\n",
    "                   #'BraTS T2 VFlip': brats_val_t2_vflip_dataloader\n",
    "}\n",
    "brats_dataloader_dict = {key: val for key, val in dataloader_dict.items() if 'BraTS' in key}\n",
    "\n",
    "for name, dataloader in dataloader_dict.items(): \n",
    "    print(f'{name:15} dataloader: {len(dataloader)} batches (batch_size: {dataloader.batch_size}) -> {len(dataloader) * dataloader.batch_size} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD Detection Evaluation for different OOD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ood_evaluations(camcan_train_dataloader, dataloader_dict, ensemble_models, residual_threshold=1.35, max_n_batches=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAIC Score Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BACTHES = 3\n",
    "\n",
    "dataloader_dict = {'BraTS T2 val': brats_val_t2_dataloader, \n",
    "                   #'BraTS T1 val': brats_val_t1_dataloader, \n",
    "                   'BraTS T2 HM val': brats_val_t2_hm_dataloader, \n",
    "                   #'BraTS T1 HM val': brats_val_t1_hm_dataloader,\n",
    "                   'CamCAN train': camcan_train_dataloader,\n",
    "                   #'Gaussian noise': noise_loader,\n",
    "                   #'MNIST': mnist_val_dataloader\n",
    "}\n",
    "\n",
    "waic_dict = run_ood_to_ood_dict(dataloader_dict, ensemble_models, num_batches=NUM_BACTHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ood_scores(waic_dict, score_label='WAIC', dataset_name_filters=['BraTS T2 val'], modes_to_include=['healthy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_least_ood(waic_dict, 'BraTS T2 val')\n",
    "plot_most_least_ood(waic_dict, 'BraTS T2 HM val')\n",
    "plot_most_least_ood(waic_dict, 'CamCAN train', do_lesional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_close_to_score(waic_dict, 'BraTS T2 val', min_score=0.95, max_score=1.2)\n",
    "plot_samples_close_to_score(waic_dict, 'BraTS T2 HM val', min_score=0.85, max_score=1.2)\n",
    "plot_samples_close_to_score(waic_dict, 'CamCAN train', do_lesional=False, min_score=0.8, max_score=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertify-env",
   "language": "python",
   "name": "uncertify-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
